# import sqlite3 # No longer needed
import os
from flask import Flask, render_template, request, redirect, url_for, jsonify, flash, session # Removed g
import datetime
import uuid # Import uuid module
from collections import defaultdict # For easier counting
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy.sql import func
from dotenv import load_dotenv
import logging # For better logging

# Load environment variables from .env file for local development
load_dotenv()

# --- Configuration ---
# DATABASE = '../survey.db' # Removed SQLite path
SECRET_KEY = os.environ.get('SECRET_KEY', os.urandom(24)) # Use env var for secret key

app = Flask(__name__)
# app.config.from_object(__name__) # Remove this if using direct config below

# --- SQLAlchemy Configuration ---
# Read DATABASE_URL from environment variable (set in Vercel)
# Fallback to a local SQLite file for development if DATABASE_URL is not set
app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('POSTGRES_URL', 'sqlite:///local_dev.db') # Use POSTGRES_URL from Vercel/Supabase
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
db = SQLAlchemy(app)

# --- Database Model ---
class Response(db.Model):
    __tablename__ = 'responses' # Optional: Define table name explicitly
    id = db.Column(db.Integer, primary_key=True)
    timestamp = db.Column(db.DateTime(timezone=True), server_default=func.now())
    response_uuid = db.Column(db.String(36), unique=True, nullable=False, default=lambda: str(uuid.uuid4())) # Use default function for UUID
    q1 = db.Column(db.Integer, nullable=True) # Allow nulls if needed
    q2 = db.Column(db.Integer, nullable=True)
    q3 = db.Column(db.Integer, nullable=True)
    q4 = db.Column(db.Integer, nullable=True)
    q5 = db.Column(db.Integer, nullable=True)
    q6 = db.Column(db.Integer, nullable=True)
    q7 = db.Column(db.Integer, nullable=True)
    q8 = db.Column(db.Integer, nullable=True)
    q9 = db.Column(db.Integer, nullable=True)
    q10 = db.Column(db.Integer, nullable=True)
    q11 = db.Column(db.Integer, nullable=True)
    q12 = db.Column(db.Integer, nullable=True)
    custom_q1 = db.Column(db.Text, nullable=True)
    custom_q2 = db.Column(db.Text, nullable=True)

    def __repr__(self):
        return f'<Response {self.response_uuid}>'

# --- New CLI command to create tables ---
@app.cli.command('create-db')
def create_db_command():
    """Creates the database tables based on SQLAlchemy models."""
    try:
        # In a production/Vercel context, you might run this once manually
        # or use a migration tool like Alembic.
        # db.drop_all() # Optional: Drop existing tables first if needed
        with app.app_context(): # Ensure context for db operations
             db.create_all()
        print('Initialized the database tables.')
    except Exception as e:
        print(f"Error creating database tables: {e}")
        logging.exception("Database creation failed")

# --- Remove SQLite Specific Code ---
# Removed get_db, close_db, init_db, initdb_command, before_request

# --- (SQLite code removed) ---

# --- Routes ---

@app.route('/')
def survey_form():
    """Displays the survey form."""
    return render_template('survey.html')

@app.route('/submit', methods=['POST'])
def submit_survey():
    """Handles survey submission."""
    try:
        # db = get_db() # Removed SQLite db access
        # --- Extract data from form ---
        # Likert scale questions (ensure they are integers 1-5)
        q_scores = {}
        for i in range(1, 13):
            q_key = f'q{i}'
            try:
                score = int(request.form.get(q_key, 0)) # Default to 0 if missing
                if not 1 <= score <= 5:
                     # Handle invalid input if necessary, maybe default or raise error
                     score = 0 # Or flash an error message
                q_scores[q_key] = score
            except (ValueError, TypeError):
                 q_scores[q_key] = 0 # Handle non-integer input

        # Custom questions
        custom_q1 = request.form.get('custom_q1', '').strip()
        custom_q2 = request.form.get('custom_q2', '').strip()

        # --- Insert into database using SQLAlchemy ---
        new_response = Response(
            # response_uuid is generated by default
            q1=q_scores.get('q1'), q2=q_scores.get('q2'), q3=q_scores.get('q3'),
            q4=q_scores.get('q4'), q5=q_scores.get('q5'), q6=q_scores.get('q6'),
            q7=q_scores.get('q7'), q8=q_scores.get('q8'), q9=q_scores.get('q9'),
            q10=q_scores.get('q10'), q11=q_scores.get('q11'), q12=q_scores.get('q12'),
            custom_q1=custom_q1,
            custom_q2=custom_q2
        )
        db.session.add(new_response)
        db.session.flush() # Flush to get the generated UUID before commit (optional but useful)
        response_uuid = new_response.response_uuid # Get the generated UUID
        db.session.commit() # Commit the transaction

        # Store the UUID in the session to link to the thank you page
        session['last_response_uuid'] = response_uuid

        flash('Thank you for completing the survey!', 'success')
        return redirect(url_for('thank_you')) # Redirect to a thank you page

    except Exception as e:
        print(f"Error processing submission: {e}") # Log the error
        flash('An error occurred while submitting your survey. Please try again.', 'error')
        return redirect(url_for('survey_form')) # Redirect back to survey on error

@app.route('/thank-you')
def thank_you():
    """Displays the styled thank you page."""
    # Get the last response UUID from the session, if it exists
    last_response_uuid = session.get('last_response_uuid')
    # Clear it from session immediately after retrieving to prevent reuse
    session.pop('last_response_uuid', None)
    return render_template('thank_you.html', response_uuid=last_response_uuid)


@app.route('/dashboard')
def dashboard():
    """Displays the dashboard page."""
    # Add authentication/authorization check here later
    return render_template('dashboard.html')

# Helper function to calculate distribution
def calculate_distribution(scores):
    """Calculates the distribution counts for a list of scores."""
    counts = {'engaged': 0, 'not_engaged': 0, 'actively_disengaged': 0}
    valid_scores = [s for s in scores if s is not None and 1 <= s <= 5]
    if not valid_scores:
        return counts, 0 # Return zero counts and total valid count

    for score in valid_scores:
        if score >= 4:
            counts['engaged'] += 1
        elif score == 3:
            counts['not_engaged'] += 1
        else: # score 1 or 2
            counts['actively_disengaged'] += 1
    return counts, len(valid_scores)

# Define question texts
QUESTION_TEXTS = {
    "Q1": {"short": "Know What's Expected", "full": "I know what is expected of me at work."},
    "Q2": {"short": "Materials and Equipment", "full": "I have the materials and equipment I need to do my work right."},
    "Q3": {"short": "Opportunity to Do Best", "full": "At work, I have the opportunity to do what I do best every day."},
    "Q4": {"short": "Recognition", "full": "In the last seven days, I have received recognition or praise for doing good work."},
    "Q5": {"short": "Cares About Me", "full": "My supervisor, or someone at work, seems to care about me as a person."},
    "Q6": {"short": "Development", "full": "There is someone at work who encourages my development."},
    "Q7": {"short": "Opinions Count", "full": "At work, my opinions seem to count."},
    "Q8": {"short": "Mission/Purpose", "full": "The mission or purpose of my company makes me feel my job is important."},
    "Q9": {"short": "Committed to Quality", "full": "My associates or fellow employees are committed to doing quality work."},
    "Q10": {"short": "Best Friend", "full": "I have a best friend at work."},
    "Q11": {"short": "Progress", "full": "In the last six months, someone at work has talked to me about my progress."},
    "Q12": {"short": "Learn and Grow", "full": "In the last year, I have had opportunities at work to learn and grow."},
}


@app.route('/dashboard/data')
def dashboard_data():
    """Provides data for the new dashboard format."""
    # Add authentication/authorization check here later
    try:
        # db = get_db() # Removed SQLite
        # cursor = db.cursor() # Removed SQLite

        # Fetch all responses using SQLAlchemy
        all_responses = Response.query.all() # List of Response objects

        num_responses = len(all_responses)
        grand_total_score = 0
        grand_valid_count = 0
        overall_distribution_counts = {'engaged': 0, 'not_engaged': 0, 'actively_disengaged': 0}
        questions_data = []

        if num_responses > 0:
            for i in range(1, 13):
                q_key = f"q{i}"
                # Extract scores for this specific question, handling potential None from DB
                # Extract scores using attribute access on Response objects
                scores_for_q = [getattr(resp, q_key) for resp in all_responses if getattr(resp, q_key) is not None]

                # Calculate average (only considering valid 1-5 scores)
                valid_scores_for_q = [s for s in scores_for_q if 1 <= s <= 5]
                num_respondents_for_q = len(valid_scores_for_q)
                average_for_q = round(sum(valid_scores_for_q) / num_respondents_for_q, 2) if num_respondents_for_q > 0 else 0

                # Calculate distribution for this question
                dist_counts, _ = calculate_distribution(scores_for_q) # Use the helper

                # Add to grand total for Grand Mean calculation
                grand_total_score += sum(valid_scores_for_q)
                grand_valid_count += num_respondents_for_q

                # Add to overall distribution counts
                overall_distribution_counts['engaged'] += dist_counts['engaged']
                overall_distribution_counts['not_engaged'] += dist_counts['not_engaged']
                overall_distribution_counts['actively_disengaged'] += dist_counts['actively_disengaged']

                questions_data.append({
                    "id": q_key.upper(),
                    "text": QUESTION_TEXTS[q_key.upper()]["full"],
                    "short_text": QUESTION_TEXTS[q_key.upper()]["short"],
                    "average": average_for_q,
                    "respondents": num_respondents_for_q,
                    # "percentile_rank": 0, # Removed placeholder
                    "distribution": dist_counts # Counts: engaged, not_engaged, actively_disengaged
                })

        # Calculate Grand Mean
        grand_mean = round(grand_total_score / grand_valid_count, 2) if grand_valid_count > 0 else 0

        # Calculate Overall Distribution Percentages
        total_overall_scores_counted = sum(overall_distribution_counts.values())
        engagement_distribution_percent = {
            "engaged_percent": round((overall_distribution_counts['engaged'] / total_overall_scores_counted) * 100) if total_overall_scores_counted > 0 else 0,
            "not_engaged_percent": round((overall_distribution_counts['not_engaged'] / total_overall_scores_counted) * 100) if total_overall_scores_counted > 0 else 0,
            "actively_disengaged_percent": round((overall_distribution_counts['actively_disengaged'] / total_overall_scores_counted) * 100) if total_overall_scores_counted > 0 else 0,
        }
        # Adjust rounding to ensure sum is 100% (optional but good practice)
        # Simple adjustment: add difference to largest category if needed
        current_total_percent = sum(engagement_distribution_percent.values())
        if total_overall_scores_counted > 0 and current_total_percent != 100:
             diff = 100 - current_total_percent
             # Find the category with the max percentage to add the difference
             max_cat = max(engagement_distribution_percent, key=engagement_distribution_percent.get)
             engagement_distribution_percent[max_cat] += diff


        # Get custom question responses using SQLAlchemy
        custom_q1_results = db.session.query(Response.custom_q1).filter(Response.custom_q1 != None, Response.custom_q1 != '').all()
        custom_q1_responses = [res[0] for res in custom_q1_results]
        custom_q2_results = db.session.query(Response.custom_q2).filter(Response.custom_q2 != None, Response.custom_q2 != '').all()
        custom_q2_responses = [res[0] for res in custom_q2_results]

        data = {
            "grand_mean": grand_mean,
            "total_responses": num_responses, # Total submissions started
            "engagement_distribution": engagement_distribution_percent, # Overall percentages
            "questions": questions_data, # List of dicts per question
            # Keeping custom responses in case they are needed later
            "custom_q1_responses": custom_q1_responses,
            "custom_q2_responses": custom_q2_responses
        }
        return jsonify(data)

    except Exception as e:
        print(f"Error fetching dashboard data: {e}")
        # Log the full traceback for debugging
        import traceback
        traceback.print_exc()
        return jsonify({"error": "Could not retrieve dashboard data"}), 500
# --- Route for viewing individual results ---
@app.route('/my-results/<string:response_uuid>') # Specify type for route variable
def my_results(response_uuid):
    """Displays the responses for a specific submission."""
    # db = get_db() # Removed SQLite
    # cursor = db.cursor() # Removed SQLite
    # cursor.execute("SELECT * FROM responses WHERE response_uuid = ?", (response_uuid,)) # Removed SQLite
    # response_data = cursor.fetchone() # Removed SQLite
    response_data = Response.query.filter_by(response_uuid=response_uuid).first() # Use SQLAlchemy

    if response_data:
        # Convert the Row object to a dictionary for easier template access
        # response_dict = dict(response_data) # Pass the object directly
        return render_template('my_results.html', response=response_data) # Pass the SQLAlchemy object
    else:
        # Handle case where UUID is not found or invalid
        flash('Could not find the specified survey response.', 'error')
        return redirect(url_for('survey_form')) # Or redirect to thank_you or an error page

# --- (Main execution block removed) ---
